{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "834cfea1",
   "metadata": {},
   "source": [
    "Pandas is a powerful and widely used open-source data manipulation and analysis library for Python. It provides easy-to-use data structures and functions needed to manipulate structured data seamlessly\n",
    "\n",
    "This guide is created with purpose of<br>\n",
    "1- Beginners get familiar with Pandas functions<br>\n",
    "2- Quick review<br>\n",
    "3- To be used as lookup to find basic and important functions all in one place. <br><br>\n",
    "\n",
    "Note:- Salary datasets is being used form Kaggle. It can be found in Dataset folder of repo or if needed to download online. (https://www.kaggle.com/datasets/kaggle/sf-salaries)\n",
    "\n",
    "Happy Coding :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041ef19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001180cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printFunction(element : object,printString=\"\"):\n",
    "    print(printString,\"\\n\",element,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa837dc1",
   "metadata": {},
   "source": [
    "### Series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b37922",
   "metadata": {},
   "source": [
    "In the context of the pandas library in Python, a Series refers to a one-dimensional labeled array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752345ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['a','b','c']\n",
    "my_data = [10,20,30]\n",
    "np_arr = np.array(my_data)\n",
    "myDict = {0:my_data,1:labels}\n",
    "\n",
    "printFunction(pd.Series(data=my_data,index=labels),\"We define a Series and gives index, This can't be done in Numpy\")\n",
    "printFunction(pd.Series(data=np_arr,index=labels),\"We define a Series through Numpy array, and gives Indexes\")\n",
    "printFunction(pd.Series(myDict),\"We define a Series through Dictionary, keys become indexes automatically\")\n",
    "pd1 = pd.Series(myDict)\n",
    "printFunction(pd1[0],\" Access the element of Series by naming index\")\n",
    "printFunction(pd1[[0,1]],\" Access Multiple element of Series by giving list of indexes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1359fb0b",
   "metadata": {},
   "source": [
    "### DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65190b9",
   "metadata": {},
   "source": [
    "In the context of the pandas library in Python, DataFrame is a two-dimensional, tabular data structure. It is one of the most widely used data structures for data analysis and manipulation. The DataFrame is similar to a spreadsheet or a SQL table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408a36d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = ['a','b','c']\n",
    "cols = ['x','y','z']\n",
    "my_data = [[10,20,30],[40,50,60],[70,80,90]]\n",
    "myDict = {\"A\":[1,2,np.nan],'B':[3,np.nan,np.nan],\"C\":[6,7,8]}\n",
    "df = pd.DataFrame(data=my_data,index=indexes,columns=cols) #Creating dataframe from Lists\n",
    "df2 = pd.DataFrame(data=myDict)  #Creating dataframe from Dictionary\n",
    "salriesDf = pd.read_csv(\"DataSets/Salaries.csv\")\n",
    "#There are others functions as well to read data from like pd.read_excel(), read_parquet etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a13fd02",
   "metadata": {},
   "source": [
    "##### Starting Functions to get to know your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c24a5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "printFunction(salriesDf.shape,\"Show Shape of Dataframe\")\n",
    "printFunction(salriesDf.head(),\"Show first few rows of Dataframe\")\n",
    "printFunction(salriesDf.tail(),\"Show last few rows of Dataframe\")\n",
    "printFunction(salriesDf.info(),\"Show information about the Dataframe\")\n",
    "printFunction(salriesDf.describe(),\"Show descriptive statistics of Dataframe\")\n",
    "printFunction(salriesDf.corr(),\"Compute and show pairwise corelations of Dataframe\")\n",
    "printFunction(salriesDf.cov(),\"Compute and show covariance matrix of Dataframe\")\n",
    "printFunction(df['x'].unique(),\"Show unique values of a column in Dataframe\")\n",
    "printFunction(df['x'].nunique(),\"Show number of unique values of a column in Dataframe\")\n",
    "printFunction(df['x'].value_counts(),\"Show values and their occurence count of a column in Dataframe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae8d889",
   "metadata": {},
   "source": [
    "##### Accessing your Dataset Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe86fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "printFunction(df,\"Now as dataframe is multidimesnional, it is collection of series along with column names\")\n",
    "printFunction(df['x'],\"You can access whole column by subscript method, but can't access row by subscript method\")\n",
    "printFunction(df.loc['a'],\"You can access whole row by subscript method using loc and index name\")\n",
    "printFunction(df.loc[['a','b']],\"You can access multiple whole rows by subscript method using loc and index names\")\n",
    "printFunction(df.iloc[0],\"You can access whole row by subscript method using iloc and index number\")\n",
    "printFunction(df.iloc[[0,1]],\"You can access multiple whole rows by subscript method using iloc and index numbers\")\n",
    "#The difference between loc and iloc is, loc require you to write names of index and column, iloc requires numbers\n",
    "printFunction(df.loc['a','x'],\"You can access a particular value of 2-d array using loc\")\n",
    "printFunction(df.loc[['a','b'],['x','y']],\"You can access a subset of 2-d array using loc\")\n",
    "printFunction(df.iloc[0,0],\"You can access a particular value of 2-d array using iloc\")\n",
    "printFunction(df.iloc[[0,1],[0,1]],\"You can access a subset of 2-d array using iloc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa23977",
   "metadata": {},
   "source": [
    "##### Adding/Dropping Columns/Rows in Dataset according to need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4eb04ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['newColumn']=df['x'] * df['y']  #Adding a column\n",
    "printFunction(df,\"After Adding a New column to DF by multiplying 2 other columns values\")\n",
    "df.drop(labels=['newColumn'],axis=1,inplace=True)#Dropping a column\n",
    "printFunction(df,\"After Dropping a column, and confirming we dont need dataframe, we need change in this dataframe through inplace\")\n",
    "printFunction(df.drop(labels=['a'],axis=0),\"After Dropping a row with index value 'a'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888a5e58",
   "metadata": {},
   "source": [
    "##### Handling of Missing Data - Imputation\n",
    "Always remember there are different ways missing data can be filled (imputated), instead of dropping the column/row.<br>\n",
    "Some are:- <br>\n",
    "1- Constant <br>\n",
    "2- Mode<br>\n",
    "3- Median (I prefer it over Mean, as less suspectible to Outliers)<br>\n",
    "4- Mean<br>\n",
    "5- Forward Fill / Backward Fill (Use last or upcoming row value)<br>\n",
    "6- Nearest Neighbour<br>\n",
    "7- Linear Regression / Multi Linear Regression<br>\n",
    "8- Deep Learning Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7ba938",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remember NAN and None/Null are theoratically different things, but in pandas/numpy treated samely, so sane result come\n",
    "printFunction(df2,\"Dataframe we are working on\")\n",
    "printFunction(df2.isna(),\"Return whole Dataframe of boolean, Check if Dataframe has NAN values\")\n",
    "printFunction(df2.isnull(),\"Return whole Dataframe of boolean, Check if Dataframe has Null values\")\n",
    "printFunction(df2.notna(),\"Return whole Dataframe of boolean, Check if Dataframe has na NAN values\")\n",
    "printFunction(df2['C'].notna(),\"Return whole column of boolean, Check if Dataframe column has no NAN values\")\n",
    "\n",
    "printFunction(df2.dropna(),\"Drop any row which has 1 or more nan value, It returns new dataframe, if you want to change this one use inplace=true\")\n",
    "printFunction(df2.dropna(axis=1),\"Drop any Cols which has 1 or more nan value, It returns new dataframe, if you want to change this one use inplace=true\")\n",
    "printFunction(df2.dropna(axis=1,thresh=2),\"Drop any Cols when total value is equal or more to threshold value\")\n",
    "printFunction(df2.dropna(axis=1,thresh=2),\"Drop any Cols when total value is equal or more to threshold value\")\n",
    "printFunction(df2.fillna(value=\"Filler\"),\"Fill all the NAN/None values of dataframe with this value, It returns new dataframe, if you want to change this one use inplace=true\")\n",
    "printFunction(df2['A'].fillna(value=df2['A'].median()),\"Fill NAN/None values of a particular column with the median of that column\")\n",
    "printFunction(df2['A'].fillna(value=df2['A'].median()),\"Fill NAN/None values of a particular column with the median of that column\")\n",
    "printFunction(df2.isna(),\"Fill NAN/None values of a particular column with the median of that column\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78d1620",
   "metadata": {},
   "source": [
    "##### Filtering Dataset for Analytics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bf5c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "printFunction(df[df>20],\"This will return a complete True/False 2d arr, and where it is False will become Nan\")\n",
    "#But we dont want Nan we want to get only those values which pass the test of a particular Column/Row\n",
    "printFunction(df[df['y']>20],\"This will return whole subset of 2d arr, which satisfy your column condition\")\n",
    "printFunction(df[(df['y']>20) & (df['z']>60)],\"This will return whole subset of 2d arr, which satisfy your columns multiple condition\")\n",
    "printFunction(df[(df['y']>20) | (df['z']>60)],\"This will return whole subset of 2d arr, which satisfy your columns multiple condition\")\n",
    "printFunction(df[(df['y']>20) & (df['z']>60)][['x','y']],\"This will return whole subset of 2d arr, which satisfy your columns multiple condition,\\\n",
    "                                                            and we are subscripting it again to get particular columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388be49d",
   "metadata": {},
   "source": [
    "##### Setting and Resetting Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18eb0feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "printFunction(df.reset_index(),\"Reset your Indexes to integers, and make a column of old indexes\")\n",
    "printFunction(df.set_index('x'),\"Set your Indexes to specified column, but will not make a new column of old indexes\")\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ba9755",
   "metadata": {},
   "source": [
    "##### GroupBy in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f932cee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "myDict = {\"Company\":[\"Google\",\"Google\",\"Microsoft\",\"Microsoft\",\"Facebook\",\"Facebook\",\"Google\"],\n",
    "          'Employee':[\"Farhan\",\"Samar\",\"Ashwin\",\"Peter\",\"Aasim\",\"Derrick\",\"Omer\"],\n",
    "          \"Salary\":[200,300,200,350,120,134,232],\n",
    "         \"Age\":[24,38,31,28,31,33,40]}\n",
    "\n",
    "employeeDf = pd.DataFrame(data=myDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c581319",
   "metadata": {},
   "outputs": [],
   "source": [
    "printFunction(salriesDf.groupby(\"JobTitle\").count()[\"Id\"],\"Groupby Job Title to see how many people have same job title\")\n",
    "printFunction(salriesDf.groupby(\"JobTitle\").mean()[\"TotalPay\"],\"Groupby Job Title to see mean pay of each job title\")\n",
    "printFunction(salriesDf.groupby(\"JobTitle\")[\"TotalPay\",\"Year\"].min(),\"Groupby Job Title to see min totalpay and Year of each job title\")\n",
    "printFunction(salriesDf.groupby(\"Year\")[\"TotalPay\"].sum(),\"Groupby Job Year to see and TotalPay sum of each year\")\n",
    "printFunction(salriesDf.groupby(\"JobTitle\")[\"TotalPay\"].describe(),\"Some statistics on TotalPay on basis of JobTitle\")\n",
    "printFunction(salriesDf.groupby(\"JobTitle\")[\"TotalPay\"].describe().loc[\"ACCOUNT CLERK\"],\"Some statistics on TotalPay of a prticular job title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8256d98c",
   "metadata": {},
   "source": [
    "##### SQL JOIN / Merging and Concatenating Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa31c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1= pd.DataFrame(data=[[1,2,3],[4,5,6]],columns=[\"A\",\"B\",\"C\"])\n",
    "df2= pd.DataFrame(data=[[7,8,9],[10,11,12]],columns=[\"A\",\"B\",\"C\"])\n",
    "df3= pd.DataFrame(data=[[13,14,15],[16,17,18]],columns=[\"A\",\"B\",\"C\"], index=[6,7])\n",
    "\n",
    "leftDf= pd.DataFrame(data=[[1,2,'A0'],[4,5,'A1'],[3,6,'B1']],columns=[\"A\",\"B\",\"key\"])\n",
    "rightDf= pd.DataFrame(data=[[7,8,'A1'],[10,11,'A0']],columns=[\"A\",\"B\",\"key\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9879c138",
   "metadata": {},
   "outputs": [],
   "source": [
    " printFunction(pd.concat([df1,df2]),\"While concatenating by Adding along columns with default axis=0, \\\n",
    " Notice How the index of both dataframes remain unchange in concatenated df\")\n",
    "printFunction(pd.concat([df1,df3]),\"While concatenating by Adding along columns with default axis=0, \\\n",
    " Notice How the index of both dataframes remain unchange in concatenated df\")\n",
    "printFunction(pd.concat([df1,df2],axis=1),\"While concatenating by Adding along rows axis=1, \\\n",
    " Notice How the index of both dataframes were same so they concantenated among indexes perfectly\")\n",
    "printFunction(pd.concat([df1,df3],axis=1),\"While concatenating by Adding along rows axis=1, \\\n",
    " Notice How the index of both dataframes were different so their concatenation yields NAN results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea4736c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge is Similar to SQL joins, so now you don't have to worry for Index matching or order of indexes. As it will join based on key\n",
    "printFunction(pd.merge(leftDf,rightDf,how='inner',on='key'),\"While merging like SQL join with inner join on column key\")\n",
    "printFunction(pd.merge(leftDf,rightDf,how='right',on='key'),\"While merging like SQL join with inner join on column key\")\n",
    "#You can add multiple keys in on sections for joining as well.\n",
    "printFunction(pd.merge(leftDf,rightDf,how='left',on=['key']),\"While merging like SQL join with left join on column key\")\n",
    "printFunction(pd.merge(leftDf,rightDf,how='outer',on=['key']),\"While merging like SQL join with outer join on column key\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d226873",
   "metadata": {},
   "source": [
    "##### Multi-Indexing Heirarchy in Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3820658e",
   "metadata": {},
   "outputs": [],
   "source": [
    "outside = ['G1','G1','G1','G2','G2','G2']\n",
    "inside = [1,2,3,1,2,3]\n",
    "hier_index = list(zip(outside,inside))\n",
    "hier_index = pd.MultiIndex.from_tuples(hier_index) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f68948e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=np.random.randn(6,2), index=hier_index, columns=['A','B'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72290bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "printFunction(df.loc['G1'].loc[3],\"Getting particular value from Multi-indexed Dataframe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44d5a31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0442eb60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
